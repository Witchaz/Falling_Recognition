{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c8fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c60143",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from src.preprocessing import normalize_csi\n",
    "from src.csi_spliter import separate_amp_phase\n",
    "from src.handle_csi_csv import split_csi_csv\n",
    "from src.data import get_dataloaders, list_of_df_to_array\n",
    "from src.model import TCN_AA\n",
    "from src.train import train\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d759bf2e",
   "metadata": {},
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(\".\")\n",
    "sys.path.insert(0, path) # location of src \n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b08c1aa",
   "metadata": {},
   "source": [
    "# Pre Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b169ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. เตรียม path\n",
    "csi_data_dir = os.path.join(path, 'csi_data')\n",
    "keypoint_csv_dir = os.path.join(path, 'keypoint_csv')\n",
    "\n",
    "# 2. อ่านไฟล์ feature และ label\n",
    "feature_files = sorted(os.listdir(csi_data_dir))\n",
    "label_files = sorted(os.listdir(keypoint_csv_dir))\n",
    "\n",
    "X = []\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15de9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for feat_file, label_file in zip(feature_files, label_files):\n",
    "    # อ่าน feature (สมมติเป็น .npy หรือ .csv)\n",
    "    X_temp = []\n",
    "    Y_temp = []\n",
    "    feat_path = os.path.join(csi_data_dir, feat_file)\n",
    "    for filename in os.listdir(feat_path):\n",
    "        file_path = os.path.join(feat_path, filename)\n",
    "        if file_path.endswith('.npy'):\n",
    "            feat = np.load(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            feat = pd.read_csv(file_path)\n",
    "        else:\n",
    "            continue  # ข้ามไฟล์ที่ไม่รู้จัก\n",
    "        \n",
    "        \n",
    "                # อ่าน label (สมมติเป็น .csv)\n",
    "        label_path = os.path.join(keypoint_csv_dir, label_file, filename)\n",
    "        label = pd.read_csv(label_path)\n",
    "\n",
    "        feat.set_index('timestamp', inplace=True)\n",
    "        label.set_index('frame_index', inplace=True)    \n",
    "        \n",
    "        feat.reset_index(drop=True, inplace=True)\n",
    "        feat.index += 1  # ให้ index เริ่มที่ 1\n",
    "\n",
    "        X_temp.append(feat)  \n",
    "        Y_temp.append(label)\n",
    "    \n",
    "    X.append(X_temp)\n",
    "    Y.append(Y_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e04671",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_norm_df_list = []\n",
    "Y_norm_df_list = []\n",
    "\n",
    "for i in range(len(X)): \n",
    "    for j in range(len(X[i])):\n",
    "        X_temp = pd.DataFrame(X[i][j])\n",
    "        Y_temp = pd.DataFrame(Y[i][j])\n",
    "        \n",
    "        X_temp = split_csi_csv(X_temp)\n",
    "\n",
    "        aligned = X_temp.merge(Y_temp, left_index=True, right_index=True)\n",
    "\n",
    "        if aligned.empty == True:\n",
    "            continue\n",
    "\n",
    "        # 2. แยก X, Y ที่ align แล้ว  \n",
    "        X_aligned = aligned[X_temp.columns]\n",
    "        Y_aligned = aligned[Y_temp.columns]\n",
    "\n",
    "        # 3. Normalize (ยกเว้น timestamp)\n",
    "        X_norm = normalize_csi(X_aligned)\n",
    "        Y_norm = normalize_csi(Y_aligned)\n",
    "\n",
    "        # 4. ถ้าต้องการ DataFrame กลับมา\n",
    "        X_norm_df = pd.DataFrame(X_norm, columns=X_aligned.columns)\n",
    "        Y_norm_df = pd.DataFrame(Y_norm, columns=Y_aligned.columns)\n",
    "\n",
    "        X_norm_df_list.append(X_norm_df)\n",
    "        Y_norm_df_list.append(Y_norm_df)\n",
    "        # X_norm_df.to_csv(\"X_norm.csv\")\n",
    "        # Y_norm_df.to_csv(\"Y_norm.csv\")\n",
    "        # aligned.to_csv(\"aligned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b3275",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee24f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, df in enumerate(X_norm_df_list):\n",
    "#     print(f\"X[{i}] shape: {df.shape}\")\n",
    "# for i, df in enumerate(Y_norm_df_list):\n",
    "#     print(f\"Y[{i}] shape: {df.shape}\")\n",
    "# 1. แบ่ง train/val (split ที่ list เลย)\n",
    "X_train_list, X_val_list, Y_train_list, Y_val_list = train_test_split(\n",
    "    X_norm_df_list, Y_norm_df_list, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. แปลง list ของ DataFrame เป็น numpy array\n",
    "X_train, Y_train = list_of_df_to_array(X_train_list, Y_train_list)\n",
    "X_val, Y_val = list_of_df_to_array(X_val_list, Y_val_list)\n",
    "\n",
    "# 3. สร้าง DataLoader\n",
    "train_loader, val_loader = get_dataloaders(X_train, Y_train, X_val, Y_val, batch_size=32)\n",
    "\n",
    "# 4. สร้างและ train model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TCN_AA(num_inputs=X_train.shape[2], num_channels=[64, 64, 64], num_classes=Y_train.shape[2]).to(device)\n",
    "# model = TCN_AA(num_inputs=X_train.shape[2], num_channels=[64, 64, 64], num_classes=Y_train.shape[1]).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "out = train(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=30)\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
